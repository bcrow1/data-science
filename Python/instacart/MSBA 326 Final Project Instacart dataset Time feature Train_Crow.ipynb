{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSBA 326 Final Project Instacart dataset_Crow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y variable is \"order_hour_of_day\" (Time feature) & Order Products Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>22352</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>3107</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>18194</td>\n",
       "      <td>prior</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>83009</td>\n",
       "      <td>prior</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>88772</td>\n",
       "      <td>prior</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>3421060</td>\n",
       "      <td>28462</td>\n",
       "      <td>prior</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>3421064</td>\n",
       "      <td>76586</td>\n",
       "      <td>prior</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>3421067</td>\n",
       "      <td>31369</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>3421072</td>\n",
       "      <td>50050</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>3421080</td>\n",
       "      <td>52726</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  user_id eval_set  order_number  order_dow  \\\n",
       "0               6    22352    prior             4          1   \n",
       "1               8     3107    prior             5          4   \n",
       "2              14    18194    prior            49          3   \n",
       "3              19    83009    prior             7          5   \n",
       "4              21    88772    prior            13          2   \n",
       "...           ...      ...      ...           ...        ...   \n",
       "1048570   3421060    28462    prior             8          0   \n",
       "1048571   3421064    76586    prior            38          5   \n",
       "1048572   3421067    31369    prior             5          3   \n",
       "1048573   3421072    50050    prior             3          3   \n",
       "1048574   3421080    52726    prior             2          1   \n",
       "\n",
       "         order_hour_of_day  days_since_prior_order  \n",
       "0                       12                      30  \n",
       "1                        6                      17  \n",
       "2                       15                       3  \n",
       "3                       17                      13  \n",
       "4                       12                       5  \n",
       "...                    ...                     ...  \n",
       "1048570                 17                      26  \n",
       "1048571                 15                       9  \n",
       "1048572                 15                      28  \n",
       "1048573                 19                      26  \n",
       "1048574                 11                       2  \n",
       "\n",
       "[1048575 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the Orders \"train\" only of Instacart dataset\n",
    "# Data subsetting done/created by Evan\n",
    "\n",
    "orders_train = pd.read_csv(\"~/Desktop/train.csv\")\n",
    "orders_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>2593147</td>\n",
       "      <td>44142</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>2593147</td>\n",
       "      <td>34969</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>2593147</td>\n",
       "      <td>33055</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>2593147</td>\n",
       "      <td>16185</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>2593147</td>\n",
       "      <td>7364</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  product_id  add_to_cart_order  reordered\n",
       "0               1       49302                  1          1\n",
       "1               1       11109                  2          1\n",
       "2               1       10246                  3          0\n",
       "3               1       49683                  4          0\n",
       "4               1       43633                  5          1\n",
       "...           ...         ...                ...        ...\n",
       "1048570   2593147       44142                  3          0\n",
       "1048571   2593147       34969                  4          1\n",
       "1048572   2593147       33055                  5          0\n",
       "1048573   2593147       16185                  6          1\n",
       "1048574   2593147        7364                  7          0\n",
       "\n",
       "[1048575 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Order_Products_Train dataset\n",
    "\n",
    "order_products_train = pd.read_csv(\"~/Desktop/order_products_train.csv\")\n",
    "order_products_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge \"Orders train\" with \"Orders_Product_Train\" csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>39612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>19660</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36</td>\n",
       "      <td>49235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>43086</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>46620</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048546</th>\n",
       "      <td>2593076</td>\n",
       "      <td>13102</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>76951.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048547</th>\n",
       "      <td>2593076</td>\n",
       "      <td>31355</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>76951.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048548</th>\n",
       "      <td>2593076</td>\n",
       "      <td>31343</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>76951.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048549</th>\n",
       "      <td>2593076</td>\n",
       "      <td>40332</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>76951.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048550</th>\n",
       "      <td>2593076</td>\n",
       "      <td>7349</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>76951.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502357 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  product_id  add_to_cart_order  reordered  user_id  \\\n",
       "8              36       39612                  1          0  79431.0   \n",
       "9              36       19660                  2          1  79431.0   \n",
       "10             36       49235                  3          0  79431.0   \n",
       "11             36       43086                  4          1  79431.0   \n",
       "12             36       46620                  5          1  79431.0   \n",
       "...           ...         ...                ...        ...      ...   \n",
       "1048546   2593076       13102                  5          0  76951.0   \n",
       "1048547   2593076       31355                  6          0  76951.0   \n",
       "1048548   2593076       31343                  7          0  76951.0   \n",
       "1048549   2593076       40332                  8          0  76951.0   \n",
       "1048550   2593076        7349                  9          1  76951.0   \n",
       "\n",
       "         order_number  order_dow  order_hour_of_day  days_since_prior_order  \n",
       "8                23.0        6.0               18.0                    30.0  \n",
       "9                23.0        6.0               18.0                    30.0  \n",
       "10               23.0        6.0               18.0                    30.0  \n",
       "11               23.0        6.0               18.0                    30.0  \n",
       "12               23.0        6.0               18.0                    30.0  \n",
       "...               ...        ...                ...                     ...  \n",
       "1048546          30.0        6.0                9.0                    30.0  \n",
       "1048547          30.0        6.0                9.0                    30.0  \n",
       "1048548          30.0        6.0                9.0                    30.0  \n",
       "1048549          30.0        6.0                9.0                    30.0  \n",
       "1048550          30.0        6.0                9.0                    30.0  \n",
       "\n",
       "[502357 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge \"Orders train\" with \"Orders_Product_Train\" csv\n",
    "# We want columns in the Right dataset to match with\n",
    "# the left. order_products_train is Left, orders_train is Right\n",
    "# When they merge, the \"train\" eval_set drops off, so the dataset is smaller\n",
    "# Removed \"eval_set\" column since it was creating errors (categorical not needed).\n",
    "\n",
    "new_data_train = pd.merge(order_products_train, orders_train, on='order_id', how=\"left\")\n",
    "new_data_train = new_data_train.dropna()\n",
    "del new_data_train['eval_set']\n",
    "new_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y variable is \"order_hour_of_day\" (Time feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>39612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>19660</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36</td>\n",
       "      <td>49235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>43086</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>46620</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>5743</td>\n",
       "      <td>45210</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>5743</td>\n",
       "      <td>27966</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>5743</td>\n",
       "      <td>20113</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>5743</td>\n",
       "      <td>7963</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1173.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>5796</td>\n",
       "      <td>397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>88848.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id  product_id  add_to_cart_order  reordered  user_id  \\\n",
       "8           36       39612                  1          0  79431.0   \n",
       "9           36       19660                  2          1  79431.0   \n",
       "10          36       49235                  3          0  79431.0   \n",
       "11          36       43086                  4          1  79431.0   \n",
       "12          36       46620                  5          1  79431.0   \n",
       "...        ...         ...                ...        ...      ...   \n",
       "2366      5743       45210                  8          1   1173.0   \n",
       "2367      5743       27966                  9          0   1173.0   \n",
       "2368      5743       20113                 10          1   1173.0   \n",
       "2369      5743        7963                 11          1   1173.0   \n",
       "2370      5796         397                  1          0  88848.0   \n",
       "\n",
       "      order_number  order_dow  days_since_prior_order  \n",
       "8             23.0        6.0                    30.0  \n",
       "9             23.0        6.0                    30.0  \n",
       "10            23.0        6.0                    30.0  \n",
       "11            23.0        6.0                    30.0  \n",
       "12            23.0        6.0                    30.0  \n",
       "...            ...        ...                     ...  \n",
       "2366          56.0        6.0                     8.0  \n",
       "2367          56.0        6.0                     8.0  \n",
       "2368          56.0        6.0                     8.0  \n",
       "2369          56.0        6.0                     8.0  \n",
       "2370          18.0        0.0                     4.0  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating a new variable so that we don't have to keep\n",
    "# re-running the above kernel. We only run whatever\n",
    "# amount is in .head() parenthesis\n",
    "# Use small amount for test. 502,357 is too large,\n",
    "# too long to run & crashes. OK run time from 1,000\n",
    "# to 3,000 rows. Smaller amount generates a better\n",
    "# accuracy score for Support Vector Classifier\n",
    "# Y variable is \"user_id\"\n",
    "\n",
    "limited_new_data_train = new_data_train.head(1000)\n",
    "\n",
    "# Preparing the data, one way\n",
    "X = limited_new_data_train.drop('order_hour_of_day', axis=1)  \n",
    "y = limited_new_data_train['order_hour_of_day']  \n",
    "colTags = list(X.columns.values)\n",
    "\n",
    "# Split into training and test sets. 70% train, 30% test model\n",
    "# Tried 100/0, get an error. Tried 95/5, runs slow & gets\n",
    "# 0.01 to 0.03 output. So not good.\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform multi-label classification using SVC (use one vs. others since SVC is a binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of multi-label classification with SVC is 0.17.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Prepare the multilabel model/classifier \"One vs. Rest\"\n",
    "# Use radial basis function \"rbf\" kernel. It can map an\n",
    "# input space in infinite dimensional space.\n",
    "# Support Vector Classifier\n",
    "\n",
    "model = OneVsRestClassifier(SVC(kernel='rbf', degree=2, C=1.0))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "acct_score = accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "print('The accuracy score of multi-label classification with SVC is {}.'.format(round(acct_score, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA on X values (input features only) first, then use oneVsRestClassifier() with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize to unit variance so that the range of all the\n",
    "# features are normalized, allowing each feature to contribute\n",
    "# approx proportionately to the final distance.\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eigenvalues \n",
      "[1.73785974 0.39129958 1.26970983 0.72366539 0.80783349 0.92489454\n",
      " 1.03351482 1.12266755]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Using the numpy.cov function, we computed the covariance matrix\n",
    "# of the standardized training data set.\n",
    "# Using the linalg.eig function, we performed the eigendecomposition,\n",
    "# which yielded a vector (eigen_vals) consisting of 13 eigenvalues and\n",
    "# corresponding eigenvectors as columns in a 13 x 13 dimensional matrix.\n",
    "\n",
    "cov_mat = np.cov(X_train_std.T)\n",
    "eigen_vals, eigen_vect = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('\\nEigenvalues \\n%s' % eigen_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature transformation\n",
    "\n",
    "# Sort the eigenpairs by descending order of the eigenvalues,\n",
    "# construct a projection matrix from the selected eigenvectors,\n",
    "# and use the projection matrix to tranform the data onto the\n",
    "# lower-dimensional subspace.\n",
    "# Start by sorting the eigenpairs by decreasing order of the eigenvalues\n",
    "# Create a 13x2 dimensional projection matrix W from the top two eigenvectors.\n",
    "\n",
    "\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vect[:, i])\n",
    "              for i in range(len(eigen_vals))]\n",
    "eigen_pairs.sort(key=lambda k: k[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix W:\n",
      " [[ 0.11156969  0.5887106 ]\n",
      " [-0.03110063 -0.24798995]\n",
      " [ 0.05865581 -0.60065483]\n",
      " [-0.31924685  0.11634586]\n",
      " [-0.29326957 -0.08072115]\n",
      " [-0.61230122 -0.25821297]\n",
      " [-0.23509003  0.33967282]\n",
      " [ 0.60418437 -0.17038414]]\n"
     ]
    }
   ],
   "source": [
    "# Creating a projection matrix\n",
    "\n",
    "w = np.hstack((eigen_pairs[0][1][:, np.newaxis],\n",
    "              eigen_pairs[1][1][:, np.newaxis]))\n",
    "print('Matrix W:\\n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Using the projection matrix, we can now transform a sample x\n",
    "# (represented as a 1x13 dimensional row vector) onto the PCA subspace,\n",
    "# the Principal Components 1 and 2.\n",
    "# We can also we can transform the entire 124 x 13 dimensional training\n",
    "# data set onto the two principal components by calculating the dot product\n",
    "\n",
    "X_train_pca = X_train_std.dot(w)\n",
    "colors = ['r', 'b', 'g']\n",
    "markers = ['s', 'x', 'o']\n",
    "\n",
    "for l, c, m in zip(np.unique(y_train), colors, markers):\n",
    "    plt.scatter(X_train_pca[y_train == l, 0],\n",
    "               X_train_pca[y_train == l, 1],\n",
    "               c=c, label=l, marker=m)\n",
    "\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA. Use training & testing from Standardize\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21692213 0.15848699]\n"
     ]
    }
   ],
   "source": [
    "# It indicates the proportion of the dataset's variance that lies\n",
    "# along the axis of each principal component\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21692213 0.15848699 0.14013297]\n"
     ]
    }
   ],
   "source": [
    "# Changed n_components to 3, seeing if there is a change\n",
    "# PC1 to PC3 add up to .5153\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21692213 0.15848699 0.14013297 0.1290048  0.11544666 0.10083493\n",
      " 0.09032895]\n"
     ]
    }
   ],
   "source": [
    "# Changed n_components to 7, to add up the ratios\n",
    "# PC1 to PC7 add up to .95115\n",
    "# 21.6% of the dataset's variance lies along the first axis,\n",
    "# 15.8% of the dataset's variance lies along the second axis\n",
    "# The further down we go with the PC, the less information is\n",
    "# carried on the axes\n",
    "# In order to meet the minimum acceptable variance of 60%,\n",
    "# we had to add up PC1 to PC4 to get to .6445.\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7950454  0.20206665]\n"
     ]
    }
   ],
   "source": [
    "# Book: Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow\n",
    "# by Aurelien Geron 2nd Edition\n",
    "# pg 225\n",
    "\n",
    "# You can set n_components to be a float between 0.0 and 1.0,\n",
    "# indicating the ratio of variance we wish to preserve\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of multi-label classification with PCA 0.7.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Prepare the multilabel classifier \"One vs. Rest\" with PCA\n",
    "model_pca = OneVsRestClassifier(SVC(kernel='rbf', degree=2, C=1.0))\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "acct_score2 = accuracy_score(y_test, model_pca.predict(X_test_pca))\n",
    "\n",
    "print('The accuracy score of multi-label classification with PCA {}.'.format(round(acct_score2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers using kfold cross validation: Standard Decision Tree, Random Forest & Adaboost try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.224000 (0.120930)\n",
      "Random Forest: 0.157000 (0.140574)\n",
      "Adaboost: 0.100000 (0.107981)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Prepare the models:\n",
    "# Standard Decision Tree Classifier,\n",
    "# Random Forest with a depth of 2\n",
    "# Adaboost Classifier on Standared Decision Tree Classifier\n",
    "# First Adaptive Boosting aka Adaboost\n",
    "# Compare them using kfold cross validation with k=10 aka \"n_splits=10\"\n",
    "\n",
    "models = []\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('Random Forest', RandomForestClassifier(max_depth=2, random_state=0)))\n",
    "models.append(('Adaboost', AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                                              n_estimators=200,\n",
    "                                              algorithm=\"SAMME.R\",\n",
    "                                              learning_rate=0.5,\n",
    "                                              random_state=42)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing algorithms by box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# Comparing algorithms by box plots\n",
    "\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions with Adaboost Classifier (F1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0]\n",
      " [ 0 11  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 15  0  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0 18  0  0  0  1  0  1  0  0  0]\n",
      " [ 0  0  0  0 23  0  2  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0 10  0  4  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  3  0  6  0  9  4  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  3  0  2  1  1  0  0  0  6  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0 16  0  0  0  3  0  0  0]\n",
      " [ 0  0  0  0  0  6  3  2  0 12  0  2  3  0  0  0]\n",
      " [ 0  0  0  0  8  0  2  0  0  0 39  3  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  4  4 11  0  0  0]\n",
      " [ 0  6  0  3  0  0  0  0  5  0 10  0  3  0  0  7]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  3  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  3  0  0  4  0  0  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         6.0       0.00      0.00      0.00         4\n",
      "         7.0       0.65      0.85      0.73        13\n",
      "         8.0       0.00      0.00      0.00        16\n",
      "         9.0       0.10      0.09      0.10        22\n",
      "        10.0       0.57      0.85      0.69        27\n",
      "        11.0       0.00      0.00      0.00        14\n",
      "        12.0       0.14      0.26      0.18        23\n",
      "        13.0       0.33      0.08      0.12        13\n",
      "        14.0       0.46      0.80      0.58        20\n",
      "        15.0       0.63      0.43      0.51        28\n",
      "        16.0       0.63      0.75      0.68        52\n",
      "        17.0       0.40      0.20      0.27        20\n",
      "        18.0       0.09      0.09      0.09        34\n",
      "        19.0       1.00      0.25      0.40         4\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        22.0       0.12      0.11      0.12         9\n",
      "\n",
      "    accuracy                           0.40       300\n",
      "   macro avg       0.38      0.36      0.34       300\n",
      "weighted avg       0.37      0.40      0.36       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Implement the Adaboost Classifier on Standared Decision Tree Classifier\n",
    "# Do a fit method to train the system\n",
    "Adaboost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                                              n_estimators=200,\n",
    "                                              algorithm=\"SAMME.R\",\n",
    "                                              learning_rate=0.5,\n",
    "                                              random_state=42)  \n",
    "Adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the test set\n",
    "y_pred = Adaboost.predict(X_test)\n",
    "\n",
    "# Run the classification report\n",
    "# Keep output to show that this is not a good classifier\n",
    "# on Time feature. Decision Tree is better.\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions with Decision Tree Classifier (F1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 16  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 22  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 14  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 23  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 28  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 52  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  1  0  0  0  0  0  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         6.0       1.00      1.00      1.00         4\n",
      "         7.0       1.00      1.00      1.00        13\n",
      "         8.0       1.00      1.00      1.00        16\n",
      "         9.0       1.00      1.00      1.00        22\n",
      "        10.0       1.00      1.00      1.00        27\n",
      "        11.0       1.00      1.00      1.00        14\n",
      "        12.0       1.00      1.00      1.00        23\n",
      "        13.0       1.00      1.00      1.00        13\n",
      "        14.0       0.87      1.00      0.93        20\n",
      "        15.0       0.97      1.00      0.98        28\n",
      "        16.0       1.00      1.00      1.00        52\n",
      "        17.0       1.00      1.00      1.00        20\n",
      "        18.0       1.00      1.00      1.00        34\n",
      "        19.0       1.00      1.00      1.00         4\n",
      "        20.0       1.00      1.00      1.00         1\n",
      "        22.0       1.00      0.56      0.71         9\n",
      "\n",
      "    accuracy                           0.99       300\n",
      "   macro avg       0.99      0.97      0.98       300\n",
      "weighted avg       0.99      0.99      0.99       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Implement the Standard Decision Tree Classifier\n",
    "# Do a fit method to train the system\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "dtreeC = DecisionTreeClassifier()  \n",
    "dtreeC.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the test set\n",
    "y_pred = dtreeC.predict(X_test)\n",
    "\n",
    "# Run the classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
