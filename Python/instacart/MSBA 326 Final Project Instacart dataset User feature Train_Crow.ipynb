{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSBA 326 Final Project Instacart dataset_Crow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y variable is \"user_id\" (Users feature) and Order Products Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>22352</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>3107</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>18194</td>\n",
       "      <td>prior</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>83009</td>\n",
       "      <td>prior</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>88772</td>\n",
       "      <td>prior</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>3421060</td>\n",
       "      <td>28462</td>\n",
       "      <td>prior</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>3421064</td>\n",
       "      <td>76586</td>\n",
       "      <td>prior</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>3421067</td>\n",
       "      <td>31369</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>3421072</td>\n",
       "      <td>50050</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>3421080</td>\n",
       "      <td>52726</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  user_id eval_set  order_number  order_dow  \\\n",
       "0               6    22352    prior             4          1   \n",
       "1               8     3107    prior             5          4   \n",
       "2              14    18194    prior            49          3   \n",
       "3              19    83009    prior             7          5   \n",
       "4              21    88772    prior            13          2   \n",
       "...           ...      ...      ...           ...        ...   \n",
       "1048570   3421060    28462    prior             8          0   \n",
       "1048571   3421064    76586    prior            38          5   \n",
       "1048572   3421067    31369    prior             5          3   \n",
       "1048573   3421072    50050    prior             3          3   \n",
       "1048574   3421080    52726    prior             2          1   \n",
       "\n",
       "         order_hour_of_day  days_since_prior_order  \n",
       "0                       12                      30  \n",
       "1                        6                      17  \n",
       "2                       15                       3  \n",
       "3                       17                      13  \n",
       "4                       12                       5  \n",
       "...                    ...                     ...  \n",
       "1048570                 17                      26  \n",
       "1048571                 15                       9  \n",
       "1048572                 15                      28  \n",
       "1048573                 19                      26  \n",
       "1048574                 11                       2  \n",
       "\n",
       "[1048575 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the Orders \"train\" only of Instacart dataset\n",
    "# Data subsetting done/created by Evan\n",
    "\n",
    "orders_train = pd.read_csv(\"~/Desktop/train.csv\")\n",
    "orders_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Using Order Products Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>2593147</td>\n",
       "      <td>44142</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>2593147</td>\n",
       "      <td>34969</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>2593147</td>\n",
       "      <td>33055</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>2593147</td>\n",
       "      <td>16185</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>2593147</td>\n",
       "      <td>7364</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  product_id  add_to_cart_order  reordered\n",
       "0               1       49302                  1          1\n",
       "1               1       11109                  2          1\n",
       "2               1       10246                  3          0\n",
       "3               1       49683                  4          0\n",
       "4               1       43633                  5          1\n",
       "...           ...         ...                ...        ...\n",
       "1048570   2593147       44142                  3          0\n",
       "1048571   2593147       34969                  4          1\n",
       "1048572   2593147       33055                  5          0\n",
       "1048573   2593147       16185                  6          1\n",
       "1048574   2593147        7364                  7          0\n",
       "\n",
       "[1048575 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Order_Products_Train dataset\n",
    "\n",
    "order_products_train = pd.read_csv(\"~/Desktop/order_products_train.csv\")\n",
    "order_products_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge \"Orders train\" with \"Orders_Product_Train\" csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>39612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>19660</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36</td>\n",
       "      <td>49235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>43086</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>46620</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>79431.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048546</th>\n",
       "      <td>2593076</td>\n",
       "      <td>13102</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>76951.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048547</th>\n",
       "      <td>2593076</td>\n",
       "      <td>31355</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>76951.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048548</th>\n",
       "      <td>2593076</td>\n",
       "      <td>31343</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>76951.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048549</th>\n",
       "      <td>2593076</td>\n",
       "      <td>40332</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>76951.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048550</th>\n",
       "      <td>2593076</td>\n",
       "      <td>7349</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>76951.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>502357 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  product_id  add_to_cart_order  reordered  user_id  \\\n",
       "8              36       39612                  1          0  79431.0   \n",
       "9              36       19660                  2          1  79431.0   \n",
       "10             36       49235                  3          0  79431.0   \n",
       "11             36       43086                  4          1  79431.0   \n",
       "12             36       46620                  5          1  79431.0   \n",
       "...           ...         ...                ...        ...      ...   \n",
       "1048546   2593076       13102                  5          0  76951.0   \n",
       "1048547   2593076       31355                  6          0  76951.0   \n",
       "1048548   2593076       31343                  7          0  76951.0   \n",
       "1048549   2593076       40332                  8          0  76951.0   \n",
       "1048550   2593076        7349                  9          1  76951.0   \n",
       "\n",
       "         order_number  order_dow  order_hour_of_day  days_since_prior_order  \n",
       "8                23.0        6.0               18.0                    30.0  \n",
       "9                23.0        6.0               18.0                    30.0  \n",
       "10               23.0        6.0               18.0                    30.0  \n",
       "11               23.0        6.0               18.0                    30.0  \n",
       "12               23.0        6.0               18.0                    30.0  \n",
       "...               ...        ...                ...                     ...  \n",
       "1048546          30.0        6.0                9.0                    30.0  \n",
       "1048547          30.0        6.0                9.0                    30.0  \n",
       "1048548          30.0        6.0                9.0                    30.0  \n",
       "1048549          30.0        6.0                9.0                    30.0  \n",
       "1048550          30.0        6.0                9.0                    30.0  \n",
       "\n",
       "[502357 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge \"Orders train\" with \"Orders_Product_Train\" csv\n",
    "# We want columns in the Right dataset to match with\n",
    "# the left. order_products_train is Left, orders_train is Right\n",
    "# When they merge, the \"train\" eval_set drops off, so the dataset is smaller\n",
    "# Removed \"eval_set\" column since it was creating errors (categorical not needed).\n",
    "\n",
    "new_data_train = pd.merge(order_products_train, orders_train, on='order_id', how=\"left\")\n",
    "new_data_train = new_data_train.dropna()\n",
    "del new_data_train['eval_set']\n",
    "new_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y variable is \"user_id\" (Users feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>39612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>19660</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36</td>\n",
       "      <td>49235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>43086</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>46620</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>5743</td>\n",
       "      <td>45210</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>5743</td>\n",
       "      <td>27966</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>5743</td>\n",
       "      <td>20113</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>5743</td>\n",
       "      <td>7963</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>5796</td>\n",
       "      <td>397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id  product_id  add_to_cart_order  reordered  order_number  \\\n",
       "8           36       39612                  1          0          23.0   \n",
       "9           36       19660                  2          1          23.0   \n",
       "10          36       49235                  3          0          23.0   \n",
       "11          36       43086                  4          1          23.0   \n",
       "12          36       46620                  5          1          23.0   \n",
       "...        ...         ...                ...        ...           ...   \n",
       "2366      5743       45210                  8          1          56.0   \n",
       "2367      5743       27966                  9          0          56.0   \n",
       "2368      5743       20113                 10          1          56.0   \n",
       "2369      5743        7963                 11          1          56.0   \n",
       "2370      5796         397                  1          0          18.0   \n",
       "\n",
       "      order_dow  order_hour_of_day  days_since_prior_order  \n",
       "8           6.0               18.0                    30.0  \n",
       "9           6.0               18.0                    30.0  \n",
       "10          6.0               18.0                    30.0  \n",
       "11          6.0               18.0                    30.0  \n",
       "12          6.0               18.0                    30.0  \n",
       "...         ...                ...                     ...  \n",
       "2366        6.0               16.0                     8.0  \n",
       "2367        6.0               16.0                     8.0  \n",
       "2368        6.0               16.0                     8.0  \n",
       "2369        6.0               16.0                     8.0  \n",
       "2370        0.0               22.0                     4.0  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating a new variable so that we don't have to keep\n",
    "# re-running the above kernel. We only run whatever\n",
    "# amount is in .head() parenthesis\n",
    "# Use small amount for test. 502,357 is too large,\n",
    "# too long to run & crashes. OK run time from 1,000\n",
    "# to 3,000 rows. Smaller amount generates a better\n",
    "# accuracy score for Support Vector Classifier\n",
    "# Y variable is \"user_id\"\n",
    "\n",
    "limited_new_data_train = new_data_train.head(1000)\n",
    "\n",
    "# Preparing the data, one way\n",
    "X = limited_new_data_train.drop('user_id', axis=1)  \n",
    "y = limited_new_data_train['user_id']  \n",
    "colTags = list(X.columns.values)\n",
    "\n",
    "# Split into training and test sets. 70% train, 30% test model\n",
    "# Tried 100/0, get an error. Tried 95/5, runs slow & gets\n",
    "# 0.01 to 0.03 output. So not good.\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform multi-label classification using SVC (use one vs. others since SVC is a binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of multi-label classification with SVC is 0.05.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Prepare the multilabel model/classifier \"One vs. Rest\"\n",
    "# Use radial basis function \"rbf\" kernel. It can map an\n",
    "# input space in infinite dimensional space.\n",
    "# Support Vector Classifier\n",
    "\n",
    "model = OneVsRestClassifier(SVC(kernel='rbf', degree=2, C=1.0))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "acct_score = accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "print('The accuracy score of multi-label classification with SVC is {}.'.format(round(acct_score, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA on X values (input features only) first, then use oneVsRestClassifier() with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize to unit variance so that the range of all the\n",
    "# features are normalized, allowing each feature to contribute\n",
    "# approx proportionately to the final distance.\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eigenvalues \n",
      "[1.7296743  1.50477644 0.38424393 0.66614151 0.86208118 0.77625687\n",
      " 1.05227126 1.03599942]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Using the numpy.cov function, we computed the covariance matrix\n",
    "# of the standardized training data set.\n",
    "# Using the linalg.eig function, we performed the eigendecomposition,\n",
    "# which yielded a vector (eigen_vals) consisting of 13 eigenvalues and\n",
    "# corresponding eigenvectors as columns in a 13 x 13 dimensional matrix.\n",
    "\n",
    "cov_mat = np.cov(X_train_std.T)\n",
    "eigen_vals, eigen_vect = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('\\nEigenvalues \\n%s' % eigen_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature transformation\n",
    "\n",
    "# Sort the eigenpairs by descending order of the eigenvalues,\n",
    "# construct a projection matrix from the selected eigenvectors,\n",
    "# and use the projection matrix to tranform the data onto the\n",
    "# lower-dimensional subspace.\n",
    "# Start by sorting the eigenpairs by decreasing order of the eigenvalues\n",
    "# Create a 13x2 dimensional projection matrix W from the top two eigenvectors.\n",
    "\n",
    "\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vect[:, i])\n",
    "              for i in range(len(eigen_vals))]\n",
    "eigen_pairs.sort(key=lambda k: k[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix W:\n",
      " [[-0.26324781  0.38587401]\n",
      " [ 0.04343725 -0.08007274]\n",
      " [ 0.08079979 -0.4654556 ]\n",
      " [ 0.33336836  0.20623562]\n",
      " [ 0.66065521  0.00773688]\n",
      " [ 0.06553055  0.43953102]\n",
      " [-0.34392186  0.47671946]\n",
      " [-0.5021045  -0.40620036]]\n"
     ]
    }
   ],
   "source": [
    "# Creating a projection matrix\n",
    "\n",
    "w = np.hstack((eigen_pairs[0][1][:, np.newaxis],\n",
    "              eigen_pairs[1][1][:, np.newaxis]))\n",
    "print('Matrix W:\\n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Using the projection matrix, we can now transform a sample x\n",
    "# (represented as a 1x13 dimensional row vector) onto the PCA subspace,\n",
    "# the Principal Components 1 and 2.\n",
    "# We can also we can transform the entire 124 x 13 dimensional training\n",
    "# data set onto the two principal components by calculating the dot product\n",
    "\n",
    "X_train_pca = X_train_std.dot(w)\n",
    "colors = ['r', 'b', 'g']\n",
    "markers = ['s', 'x', 'o']\n",
    "\n",
    "for l, c, m in zip(np.unique(y_train), colors, markers):\n",
    "    plt.scatter(X_train_pca[y_train == l, 0],\n",
    "               X_train_pca[y_train == l, 1],\n",
    "               c=c, label=l, marker=m)\n",
    "\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA. Use training & testing from Standardize\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21590042 0.18782835]\n"
     ]
    }
   ],
   "source": [
    "# It indicates the proportion of the dataset's variance that lies\n",
    "# along the axis of each principal component\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21590042 0.18782835 0.131346  ]\n"
     ]
    }
   ],
   "source": [
    "# Changed n_components to 3, seeing if there is a change\n",
    "# PC1 to PC3 add up to .5350\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21590042 0.18782835 0.131346   0.12931493 0.1076062  0.09689349\n",
      " 0.08314873]\n"
     ]
    }
   ],
   "source": [
    "# Changed n_components to 7, to add up the ratios\n",
    "# PC1 to PC7 add up to .9518\n",
    "# 21.5% of the dataset's variance lies along the first axis,\n",
    "# 18.7% of the dataset's variance lies along the second axis\n",
    "# The further down we go with the PC, the less information is\n",
    "# carried on the axes\n",
    "pca = PCA(n_components=7)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98592117]\n"
     ]
    }
   ],
   "source": [
    "# Book: Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow\n",
    "# by Aurelien Geron 2nd Edition\n",
    "# pg 225\n",
    "\n",
    "# You can set n_components to be a float between 0.0 and 1.0,\n",
    "# indicating the ratio of variance we wish to preserve\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of multi-label classification with PCA 0.82.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Prepare the multilabel classifier \"One vs. Rest\" with PCA\n",
    "model_pca = OneVsRestClassifier(SVC(kernel='rbf', degree=2, C=1.0))\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "acct_score2 = accuracy_score(y_test, model_pca.predict(X_test_pca))\n",
    "\n",
    "print('The accuracy score of multi-label classification with PCA {}.'.format(round(acct_score2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers using kfold cross validation: Standard Decision Tree, Random Forest & Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.160000 (0.132514)\n",
      "Random Forest: 0.010000 (0.026833)\n",
      "Adaboost: 0.160000 (0.129306)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Prepare the models:\n",
    "# Standard Decision Tree Classifier,\n",
    "# Random Forest with a depth of 2\n",
    "# Adaboost Classifier on Standared Decision Tree Classifier\n",
    "# First Adaptive Boosting aka Adaboost\n",
    "# Compare them using kfold cross validation with k=10 aka \"n_splits=10\"\n",
    "\n",
    "models = []\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('Random Forest', RandomForestClassifier(max_depth=2, random_state=0)))\n",
    "models.append(('Adaboost', AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                                              n_estimators=200,\n",
    "                                              algorithm=\"SAMME.R\",\n",
    "                                              learning_rate=0.5,\n",
    "                                              random_state=42)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing algorithms by box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# Comparing algorithms by box plots\n",
    "\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions with Adaboost Classifier (F1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 0 4 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       286.0       1.00      1.00      1.00         1\n",
      "       310.0       1.00      1.00      1.00         2\n",
      "       605.0       1.00      1.00      1.00         4\n",
      "       816.0       0.82      1.00      0.90        14\n",
      "      1173.0       1.00      1.00      1.00         7\n",
      "      2156.0       1.00      1.00      1.00         6\n",
      "      2454.0       1.00      1.00      1.00         4\n",
      "      5403.0       1.00      1.00      1.00         2\n",
      "      6990.0       1.00      1.00      1.00         2\n",
      "      7172.0       1.00      1.00      1.00         2\n",
      "      7258.0       1.00      1.00      1.00         2\n",
      "      7691.0       0.89      1.00      0.94         8\n",
      "     12762.0       1.00      1.00      1.00         5\n",
      "     14499.0       1.00      1.00      1.00         7\n",
      "     16111.0       0.50      1.00      0.67         1\n",
      "     17227.0       1.00      1.00      1.00         1\n",
      "     19636.0       0.33      1.00      0.50         1\n",
      "     20433.0       1.00      1.00      1.00         4\n",
      "     21265.0       1.00      1.00      1.00         1\n",
      "     21272.0       1.00      1.00      1.00         1\n",
      "     21515.0       1.00      1.00      1.00         4\n",
      "     21721.0       0.00      0.00      0.00         3\n",
      "     22622.0       1.00      1.00      1.00         3\n",
      "     23057.0       1.00      1.00      1.00         6\n",
      "     23856.0       1.00      1.00      1.00         1\n",
      "     26430.0       1.00      1.00      1.00         2\n",
      "     27366.0       1.00      1.00      1.00         4\n",
      "     27766.0       1.00      1.00      1.00         2\n",
      "     29889.0       1.00      1.00      1.00         3\n",
      "     30038.0       0.00      0.00      0.00         1\n",
      "     31162.0       1.00      1.00      1.00         2\n",
      "     31467.0       1.00      1.00      1.00         1\n",
      "     32573.0       0.75      1.00      0.86         3\n",
      "     32789.0       1.00      1.00      1.00         4\n",
      "     34221.0       1.00      1.00      1.00         2\n",
      "     34285.0       0.00      0.00      0.00         2\n",
      "     40150.0       1.00      1.00      1.00        11\n",
      "     40556.0       1.00      1.00      1.00         3\n",
      "     41555.0       1.00      1.00      1.00         5\n",
      "     41751.0       1.00      1.00      1.00         1\n",
      "     42756.0       1.00      1.00      1.00         3\n",
      "     43058.0       1.00      1.00      1.00         3\n",
      "     43745.0       1.00      1.00      1.00        10\n",
      "     45744.0       1.00      1.00      1.00         1\n",
      "     47475.0       0.00      0.00      0.00         3\n",
      "     51011.0       1.00      1.00      1.00         4\n",
      "     51956.0       1.00      1.00      1.00         7\n",
      "     52304.0       1.00      1.00      1.00         3\n",
      "     53847.0       1.00      1.00      1.00         8\n",
      "     54174.0       0.00      0.00      0.00         3\n",
      "     55706.0       1.00      1.00      1.00         2\n",
      "     56463.0       1.00      1.00      1.00        15\n",
      "     59631.0       1.00      1.00      1.00         7\n",
      "     61911.0       1.00      1.00      1.00         3\n",
      "     66177.0       1.00      1.00      1.00         7\n",
      "     67699.0       1.00      1.00      1.00         1\n",
      "     68007.0       0.69      1.00      0.82         9\n",
      "     68146.0       1.00      1.00      1.00         3\n",
      "     70577.0       1.00      1.00      1.00         1\n",
      "     70749.0       1.00      1.00      1.00         2\n",
      "     71669.0       1.00      1.00      1.00         3\n",
      "     71778.0       1.00      1.00      1.00        10\n",
      "     71899.0       1.00      1.00      1.00         4\n",
      "     75490.0       1.00      1.00      1.00         3\n",
      "     78126.0       1.00      1.00      1.00         4\n",
      "     79431.0       1.00      1.00      1.00         3\n",
      "     79725.0       1.00      1.00      1.00         3\n",
      "     80403.0       1.00      1.00      1.00         3\n",
      "     82113.0       1.00      1.00      1.00         1\n",
      "     83942.0       1.00      1.00      1.00         2\n",
      "     85243.0       1.00      1.00      1.00         4\n",
      "     87436.0       1.00      1.00      1.00         2\n",
      "     88848.0       0.00      0.00      0.00         1\n",
      "     90543.0       1.00      1.00      1.00         6\n",
      "     92382.0       0.00      0.00      0.00         1\n",
      "     94042.0       1.00      1.00      1.00         2\n",
      "     94991.0       1.00      1.00      1.00         3\n",
      "     95044.0       1.00      1.00      1.00         3\n",
      "     96497.0       1.00      1.00      1.00         2\n",
      "     96792.0       0.00      0.00      0.00         1\n",
      "     97381.0       0.00      0.00      0.00         0\n",
      "     97409.0       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.87      0.89      0.87       300\n",
      "weighted avg       0.92      0.95      0.93       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Implement the Adaboost Classifier on Standared Decision Tree Classifier\n",
    "# Do a fit method to train the system\n",
    "Adaboost = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                                              n_estimators=200,\n",
    "                                              algorithm=\"SAMME.R\",\n",
    "                                              learning_rate=0.5,\n",
    "                                              random_state=42)  \n",
    "Adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the test set\n",
    "y_pred = Adaboost.predict(X_test)\n",
    "\n",
    "# Run the classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
