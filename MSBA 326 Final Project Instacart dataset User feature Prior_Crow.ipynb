{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSBA 326 Final Project Instacart dataset_Crow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y variable is \"user_id\" (Users feature) & Order Products Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>22352</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>3107</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>18194</td>\n",
       "      <td>prior</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>83009</td>\n",
       "      <td>prior</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>88772</td>\n",
       "      <td>prior</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>3421060</td>\n",
       "      <td>28462</td>\n",
       "      <td>prior</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>3421064</td>\n",
       "      <td>76586</td>\n",
       "      <td>prior</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>3421067</td>\n",
       "      <td>31369</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>3421072</td>\n",
       "      <td>50050</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>3421080</td>\n",
       "      <td>52726</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  user_id eval_set  order_number  order_dow  \\\n",
       "0               6    22352    prior             4          1   \n",
       "1               8     3107    prior             5          4   \n",
       "2              14    18194    prior            49          3   \n",
       "3              19    83009    prior             7          5   \n",
       "4              21    88772    prior            13          2   \n",
       "...           ...      ...      ...           ...        ...   \n",
       "1048570   3421060    28462    prior             8          0   \n",
       "1048571   3421064    76586    prior            38          5   \n",
       "1048572   3421067    31369    prior             5          3   \n",
       "1048573   3421072    50050    prior             3          3   \n",
       "1048574   3421080    52726    prior             2          1   \n",
       "\n",
       "         order_hour_of_day  days_since_prior_order  \n",
       "0                       12                      30  \n",
       "1                        6                      17  \n",
       "2                       15                       3  \n",
       "3                       17                      13  \n",
       "4                       12                       5  \n",
       "...                    ...                     ...  \n",
       "1048570                 17                      26  \n",
       "1048571                 15                       9  \n",
       "1048572                 15                      28  \n",
       "1048573                 19                      26  \n",
       "1048574                 11                       2  \n",
       "\n",
       "[1048575 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the Orders \"train\" only of Instacart dataset\n",
    "# Data subsetting done/created by Evan\n",
    "\n",
    "orders_train = pd.read_csv(\"~/Desktop/train.csv\")\n",
    "orders_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Order Products Prior dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>33120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28985</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9327</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>45918</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>30035</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434484</th>\n",
       "      <td>3421083</td>\n",
       "      <td>39678</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434485</th>\n",
       "      <td>3421083</td>\n",
       "      <td>11352</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434486</th>\n",
       "      <td>3421083</td>\n",
       "      <td>4600</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434487</th>\n",
       "      <td>3421083</td>\n",
       "      <td>24852</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434488</th>\n",
       "      <td>3421083</td>\n",
       "      <td>5020</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32434489 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id  product_id  add_to_cart_order  reordered\n",
       "0                2       33120                  1          1\n",
       "1                2       28985                  2          1\n",
       "2                2        9327                  3          0\n",
       "3                2       45918                  4          1\n",
       "4                2       30035                  5          0\n",
       "...            ...         ...                ...        ...\n",
       "32434484   3421083       39678                  6          1\n",
       "32434485   3421083       11352                  7          0\n",
       "32434486   3421083        4600                  8          0\n",
       "32434487   3421083       24852                  9          1\n",
       "32434488   3421083        5020                 10          1\n",
       "\n",
       "[32434489 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Order_Products_Prior dataset\n",
    "\n",
    "order_products_train = pd.read_csv(\"~/Desktop/order_products_prior.csv\")\n",
    "order_products_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge \"Orders train\" with \"Orders_Product_Prior\" csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6</td>\n",
       "      <td>40462</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22352.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6</td>\n",
       "      <td>15873</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22352.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6</td>\n",
       "      <td>41897</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22352.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>8</td>\n",
       "      <td>23423</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3107.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>14</td>\n",
       "      <td>20392</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18194.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434460</th>\n",
       "      <td>3421080</td>\n",
       "      <td>31717</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>52726.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434461</th>\n",
       "      <td>3421080</td>\n",
       "      <td>12935</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>52726.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434462</th>\n",
       "      <td>3421080</td>\n",
       "      <td>25122</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>52726.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434463</th>\n",
       "      <td>3421080</td>\n",
       "      <td>10667</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>52726.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32434464</th>\n",
       "      <td>3421080</td>\n",
       "      <td>38061</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>52726.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9949768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id  product_id  add_to_cart_order  reordered  user_id  \\\n",
       "56               6       40462                  1          0  22352.0   \n",
       "57               6       15873                  2          0  22352.0   \n",
       "58               6       41897                  3          0  22352.0   \n",
       "61               8       23423                  1          1   3107.0   \n",
       "125             14       20392                  1          1  18194.0   \n",
       "...            ...         ...                ...        ...      ...   \n",
       "32434460   3421080       31717                  5          0  52726.0   \n",
       "32434461   3421080       12935                  6          1  52726.0   \n",
       "32434462   3421080       25122                  7          0  52726.0   \n",
       "32434463   3421080       10667                  8          0  52726.0   \n",
       "32434464   3421080       38061                  9          0  52726.0   \n",
       "\n",
       "          order_number  order_dow  order_hour_of_day  days_since_prior_order  \n",
       "56                 4.0        1.0               12.0                    30.0  \n",
       "57                 4.0        1.0               12.0                    30.0  \n",
       "58                 4.0        1.0               12.0                    30.0  \n",
       "61                 5.0        4.0                6.0                    17.0  \n",
       "125               49.0        3.0               15.0                     3.0  \n",
       "...                ...        ...                ...                     ...  \n",
       "32434460           2.0        1.0               11.0                     2.0  \n",
       "32434461           2.0        1.0               11.0                     2.0  \n",
       "32434462           2.0        1.0               11.0                     2.0  \n",
       "32434463           2.0        1.0               11.0                     2.0  \n",
       "32434464           2.0        1.0               11.0                     2.0  \n",
       "\n",
       "[9949768 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge \"Orders train\" with \"Orders_Product_Prior\" csv\n",
    "# We want columns in the Right dataset to match with\n",
    "# the left. order_products_Prior is Left, orders_train is Right\n",
    "# When they merge, the \"train\" eval_set drops off, so the dataset is smaller???\n",
    "# Removed \"eval_set\" column since it was creating errors (categorical not needed).\n",
    "\n",
    "new_data_train = pd.merge(order_products_train, orders_train, on='order_id', how=\"left\")\n",
    "new_data_train = new_data_train.dropna()\n",
    "del new_data_train['eval_set']\n",
    "new_data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y variable is \"user_id\" (Users feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6</td>\n",
       "      <td>40462</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>6</td>\n",
       "      <td>15873</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>6</td>\n",
       "      <td>41897</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>8</td>\n",
       "      <td>23423</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>14</td>\n",
       "      <td>20392</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>302</td>\n",
       "      <td>30391</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>302</td>\n",
       "      <td>22034</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>302</td>\n",
       "      <td>4086</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>302</td>\n",
       "      <td>260</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>304</td>\n",
       "      <td>13198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_id  product_id  add_to_cart_order  reordered  order_number  \\\n",
       "56           6       40462                  1          0           4.0   \n",
       "57           6       15873                  2          0           4.0   \n",
       "58           6       41897                  3          0           4.0   \n",
       "61           8       23423                  1          1           5.0   \n",
       "125         14       20392                  1          1          49.0   \n",
       "...        ...         ...                ...        ...           ...   \n",
       "2801       302       30391                 10          1          12.0   \n",
       "2802       302       22034                 11          0          12.0   \n",
       "2803       302        4086                 12          0          12.0   \n",
       "2804       302         260                 13          0          12.0   \n",
       "2808       304       13198                  1          1          58.0   \n",
       "\n",
       "      order_dow  order_hour_of_day  days_since_prior_order  \n",
       "56          1.0               12.0                    30.0  \n",
       "57          1.0               12.0                    30.0  \n",
       "58          1.0               12.0                    30.0  \n",
       "61          4.0                6.0                    17.0  \n",
       "125         3.0               15.0                     3.0  \n",
       "...         ...                ...                     ...  \n",
       "2801        5.0               12.0                     8.0  \n",
       "2802        5.0               12.0                     8.0  \n",
       "2803        5.0               12.0                     8.0  \n",
       "2804        5.0               12.0                     8.0  \n",
       "2808        1.0               13.0                     2.0  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Creating a new variable so that we don't have to keep\n",
    "# re-running the above kernel. We only run whatever\n",
    "# amount is in .head() parenthesis\n",
    "# Use small amount for test. 502,357 is too large,\n",
    "# too long to run & crashes. OK run time from 1,000\n",
    "# to 3,000 rows. Smaller amount generates a better\n",
    "# accuracy score for Support Vector Classifier\n",
    "# Y variable is \"user_id\"\n",
    "\n",
    "limited_new_data_train = new_data_train.head(1000)\n",
    "\n",
    "# Preparing the data, one way\n",
    "X = limited_new_data_train.drop('user_id', axis=1)  \n",
    "y = limited_new_data_train['user_id']  \n",
    "colTags = list(X.columns.values)\n",
    "\n",
    "# Split into training and test sets. 70% train, 30% test model\n",
    "# Tried 100/0, get an error. Tried 95/5, runs slow & gets\n",
    "# 0.01 to 0.03 output. So not good.\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform multi-label classification using SVC (use one vs. others since SVC is a binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of multi-label classification with SVC is 0.02.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Prepare the multilabel model/classifier \"One vs. Rest\"\n",
    "# Use radial basis function \"rbf\" kernel. It can map an\n",
    "# input space in infinite dimensional space.\n",
    "# Support Vector Classifier\n",
    "\n",
    "model = OneVsRestClassifier(SVC(kernel='rbf', degree=2, C=1.0))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "acct_score = accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "print('The accuracy score of multi-label classification with SVC is {}.'.format(round(acct_score, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA on X values (input features only) first, then use oneVsRestClassifier() with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize to unit variance so that the range of all the\n",
    "# features are normalized, allowing each feature to contribute\n",
    "# approx proportionately to the final distance.\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eigenvalues \n",
      "[0.5121144  1.437851   0.83821616 1.16605407 1.10320079 0.93542029\n",
      " 1.02420613 0.99438207]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Using the numpy.cov function, we computed the covariance matrix\n",
    "# of the standardized training data set.\n",
    "# Using the linalg.eig function, we performed the eigendecomposition,\n",
    "# which yielded a vector (eigen_vals) consisting of 13 eigenvalues and\n",
    "# corresponding eigenvectors as columns in a 13 x 13 dimensional matrix.\n",
    "\n",
    "cov_mat = np.cov(X_train_std.T)\n",
    "eigen_vals, eigen_vect = np.linalg.eig(cov_mat)\n",
    "\n",
    "print('\\nEigenvalues \\n%s' % eigen_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = sum(eigen_vals)\n",
    "var_exp = [(i / tot) for i in sorted(eigen_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature transformation\n",
    "\n",
    "# Sort the eigenpairs by descending order of the eigenvalues,\n",
    "# construct a projection matrix from the selected eigenvectors,\n",
    "# and use the projection matrix to tranform the data onto the\n",
    "# lower-dimensional subspace.\n",
    "# Start by sorting the eigenpairs by decreasing order of the eigenvalues\n",
    "# Create a 13x2 dimensional projection matrix W from the top two eigenvectors.\n",
    "\n",
    "\n",
    "eigen_pairs = [(np.abs(eigen_vals[i]), eigen_vect[:, i])\n",
    "              for i in range(len(eigen_vals))]\n",
    "eigen_pairs.sort(key=lambda k: k[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix W:\n",
      " [[ 0.04200322 -0.23995599]\n",
      " [ 0.06455102 -0.42914903]\n",
      " [ 0.11349808 -0.59817124]\n",
      " [-0.54741915  0.26133788]\n",
      " [-0.68028822 -0.07213484]\n",
      " [-0.13829805 -0.31507227]\n",
      " [-0.24493045  0.08025574]\n",
      " [ 0.37364423  0.47035195]]\n"
     ]
    }
   ],
   "source": [
    "# Creating a projection matrix\n",
    "\n",
    "w = np.hstack((eigen_pairs[0][1][:, np.newaxis],\n",
    "              eigen_pairs[1][1][:, np.newaxis]))\n",
    "print('Matrix W:\\n', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Using the projection matrix, we can now transform a sample x\n",
    "# (represented as a 1x13 dimensional row vector) onto the PCA subspace,\n",
    "# the Principal Components 1 and 2.\n",
    "# We can also we can transform the entire 124 x 13 dimensional training\n",
    "# data set onto the two principal components by calculating the dot product\n",
    "\n",
    "X_train_pca = X_train_std.dot(w)\n",
    "colors = ['r', 'b', 'g']\n",
    "markers = ['s', 'x', 'o']\n",
    "\n",
    "for l, c, m in zip(np.unique(y_train), colors, markers):\n",
    "    plt.scatter(X_train_pca[y_train == l, 0],\n",
    "               X_train_pca[y_train == l, 1],\n",
    "               c=c, label=l, marker=m)\n",
    "\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA. Use training & testing from Standardize\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17947462 0.14554853]\n"
     ]
    }
   ],
   "source": [
    "# It indicates the proportion of the dataset's variance that lies\n",
    "# along the axis of each principal component\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17947462 0.14554853 0.1377031 ]\n"
     ]
    }
   ],
   "source": [
    "# Changed n_components to 3, seeing if there is a change\n",
    "# PC1 to PC3 add up to .XX\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17947462 0.14554853 0.1377031  0.12784287 0.12412019 0.1167605\n",
      " 0.10462734]\n"
     ]
    }
   ],
   "source": [
    "# Changed n_components to 7, to add up the ratios\n",
    "# PC1 to PC7 add up to .XX\n",
    "# 17.9% of the dataset's variance lies along the first axis,\n",
    "# 14.5% of the dataset's variance lies along the second axis\n",
    "# The further down we go with the PC, the less information is\n",
    "# carried on the axes\n",
    "pca = PCA(n_components=7)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99996395]\n"
     ]
    }
   ],
   "source": [
    "# Book: Hands-on Machine Learning with Scikit-Learn, Keras & TensorFlow\n",
    "# by Aurelien Geron 2nd Edition\n",
    "# pg 225\n",
    "\n",
    "# You can set n_components to be a float between 0.0 and 1.0,\n",
    "# indicating the ratio of variance we wish to preserve\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of multi-label classification with PCA 0.75.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Prepare the multilabel classifier \"One vs. Rest\" with PCA\n",
    "model_pca = OneVsRestClassifier(SVC(kernel='rbf', degree=2, C=1.0))\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "\n",
    "acct_score2 = accuracy_score(y_test, model_pca.predict(X_test_pca))\n",
    "\n",
    "print('The accuracy score of multi-label classification with PCA {}.'.format(round(acct_score2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers using kfold cross validation: Standard Decision Tree, Random Forest & Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CART: 0.121000 (0.047000)\n",
      "Random Forest: 0.033000 (0.057280)\n",
      "Adaboost: 0.112000 (0.070399)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# Prepare the models:\n",
    "# Standard Decision Tree Classifier,\n",
    "# Random Forest with a depth of 2\n",
    "# Adaboost Classifier on Standared Decision Tree Classifier\n",
    "# First Adaptive Boosting aka Adaboost\n",
    "# Compare them using kfold cross validation with k=10 aka \"n_splits=10\"\n",
    "\n",
    "models = []\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('Random Forest', RandomForestClassifier(max_depth=2, random_state=0)))\n",
    "models.append(('Adaboost', AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                                              n_estimators=200,\n",
    "                                              algorithm=\"SAMME.R\",\n",
    "                                              learning_rate=0.5,\n",
    "                                              random_state=42)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7)\n",
    "    cv_results = cross_val_score(model, X, y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing algorithms by box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# Comparing algorithms by box plots\n",
    "\n",
    "fig = pyplot.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "pyplot.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions with Decision Tree Classifier (F1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 7 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 2 0 0]\n",
      " [0 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       382.0       1.00      1.00      1.00         1\n",
      "       971.0       0.00      0.00      0.00         1\n",
      "      1059.0       1.00      1.00      1.00         7\n",
      "      3321.0       1.00      1.00      1.00         4\n",
      "      4076.0       0.75      1.00      0.86         3\n",
      "      4209.0       1.00      1.00      1.00         2\n",
      "      4645.0       1.00      1.00      1.00         1\n",
      "      4988.0       1.00      1.00      1.00         5\n",
      "      5189.0       1.00      1.00      1.00         1\n",
      "      8456.0       1.00      1.00      1.00         1\n",
      "      8841.0       1.00      1.00      1.00         2\n",
      "     14264.0       1.00      1.00      1.00         9\n",
      "     15608.0       1.00      1.00      1.00         5\n",
      "     16288.0       1.00      1.00      1.00         4\n",
      "     16694.0       1.00      1.00      1.00         2\n",
      "     17547.0       1.00      1.00      1.00         1\n",
      "     18194.0       1.00      1.00      1.00         4\n",
      "     18409.0       1.00      1.00      1.00         1\n",
      "     18783.0       1.00      1.00      1.00         4\n",
      "     21336.0       1.00      1.00      1.00         3\n",
      "     21425.0       1.00      1.00      1.00         2\n",
      "     21551.0       1.00      1.00      1.00         3\n",
      "     21630.0       1.00      1.00      1.00         2\n",
      "     22352.0       1.00      1.00      1.00         2\n",
      "     24173.0       1.00      1.00      1.00         1\n",
      "     24721.0       1.00      1.00      1.00         3\n",
      "     25967.0       1.00      1.00      1.00         3\n",
      "     26030.0       1.00      1.00      1.00         5\n",
      "     26599.0       1.00      1.00      1.00         1\n",
      "     26978.0       1.00      1.00      1.00         3\n",
      "     29096.0       1.00      1.00      1.00         6\n",
      "     30618.0       1.00      1.00      1.00         1\n",
      "     30822.0       0.67      1.00      0.80         4\n",
      "     33094.0       1.00      1.00      1.00         3\n",
      "     34016.0       1.00      1.00      1.00         1\n",
      "     34840.0       0.00      0.00      0.00         2\n",
      "     34858.0       1.00      1.00      1.00         6\n",
      "     35569.0       1.00      1.00      1.00         2\n",
      "     39287.0       1.00      1.00      1.00         4\n",
      "     41155.0       1.00      1.00      1.00         5\n",
      "     41523.0       1.00      1.00      1.00         5\n",
      "     41591.0       1.00      1.00      1.00         2\n",
      "     43756.0       1.00      1.00      1.00         6\n",
      "     44103.0       0.00      0.00      0.00         1\n",
      "     46527.0       1.00      1.00      1.00         1\n",
      "     47358.0       1.00      1.00      1.00         3\n",
      "     48308.0       1.00      1.00      1.00         7\n",
      "     51178.0       1.00      1.00      1.00         6\n",
      "     52205.0       1.00      1.00      1.00         2\n",
      "     53965.0       1.00      1.00      1.00         8\n",
      "     54878.0       1.00      1.00      1.00         9\n",
      "     55713.0       0.00      0.00      0.00         1\n",
      "     56022.0       1.00      1.00      1.00         8\n",
      "     56896.0       1.00      1.00      1.00         6\n",
      "     57561.0       1.00      1.00      1.00         3\n",
      "     58122.0       1.00      1.00      1.00         1\n",
      "     58701.0       1.00      1.00      1.00         3\n",
      "     59897.0       1.00      1.00      1.00         4\n",
      "     62481.0       1.00      0.50      0.67         2\n",
      "     62781.0       0.00      0.00      0.00         2\n",
      "     62875.0       1.00      1.00      1.00         3\n",
      "     66104.0       1.00      1.00      1.00         6\n",
      "     66567.0       1.00      1.00      1.00         2\n",
      "     67140.0       1.00      1.00      1.00         4\n",
      "     68303.0       1.00      1.00      1.00         4\n",
      "     68572.0       1.00      1.00      1.00         6\n",
      "     69984.0       1.00      1.00      1.00         5\n",
      "     72973.0       1.00      1.00      1.00         3\n",
      "     73241.0       1.00      1.00      1.00         5\n",
      "     73310.0       1.00      1.00      1.00         1\n",
      "     73399.0       1.00      1.00      1.00         3\n",
      "     76870.0       1.00      1.00      1.00         1\n",
      "     78634.0       1.00      1.00      1.00         4\n",
      "     82764.0       1.00      1.00      1.00         5\n",
      "     83499.0       0.00      0.00      0.00         0\n",
      "     86865.0       1.00      1.00      1.00         4\n",
      "     88772.0       1.00      1.00      1.00         1\n",
      "     91667.0       1.00      1.00      1.00         4\n",
      "     91891.0       0.67      0.80      0.73         5\n",
      "     91926.0       1.00      1.00      1.00         4\n",
      "     92052.0       0.00      0.00      0.00         0\n",
      "     92123.0       1.00      1.00      1.00         2\n",
      "     92707.0       1.00      1.00      1.00         3\n",
      "     93764.0       1.00      1.00      1.00         2\n",
      "     94330.0       1.00      1.00      1.00         2\n",
      "     95044.0       1.00      1.00      1.00         6\n",
      "     96385.0       1.00      1.00      1.00         3\n",
      "     96511.0       1.00      1.00      1.00         1\n",
      "     96828.0       1.00      1.00      1.00         4\n",
      "     97039.0       1.00      1.00      1.00         2\n",
      "     97664.0       1.00      1.00      1.00         1\n",
      "     98256.0       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.97       300\n",
      "   macro avg       0.91      0.92      0.91       300\n",
      "weighted avg       0.96      0.97      0.97       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Implement the Standard Decision Tree Classifier\n",
    "# Do a fit method to train the system\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "dtreeC = DecisionTreeClassifier()  \n",
    "dtreeC.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the test set\n",
    "y_pred = dtreeC.predict(X_test)\n",
    "\n",
    "# Run the classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
